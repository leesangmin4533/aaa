> **[AI 에이전트 주의사항]**
> 이 문서는 프로젝트의 현재 아키텍처와 표준 작업 절차를 정의하는 최상위 가이드입니다.
> 
> 1.  **선행 확인:** 모든 작업을 시작하기 전, 반드시 이 문서를 먼저 읽고 전체 구조를 파악한 후 작업을 진행하십시오.
> 2.  **문서 업데이트 의무:** 코드 또는 아키텍처에 대한 주요 변경 작업이 완료되면, **반드시 이 문서의 내용도 최신 상태로 업데이트하고 '변경 이력'에 해당 내용을 기록해야 합니다.**

# BGF 자동화 프로젝트 실행 가이드

## 1. 핵심 아키텍처: 파이프라인 분리

이 프로젝트는 **예측 파이프라인**과 **학습 파이프라인**이라는 두 개의 독립적인 파이프라인으로 구성됩니다. 이는 시스템의 효율성, 확장성, 안정성을 확보하기 위함입니다.

### 1.1. 예측 파이프라인 (Prediction Pipeline)

- **핵심 파일:** `main.py`, `app.py`
- **역할:** 데이터 수집 및 **예측**.
- **실행 주기:** 매시간 (자주 실행).
- **동작 방식:**
    1. 최신 판매 데이터를 수집하여 DB에 추가합니다.
    2. 미리 학습된 모델(`tuned_models/*.pkl`)을 불러옵니다.
    3. 최신 데이터를 기반으로 판매량을 **예측**하고 결과를 DB에 저장합니다.
- **특징:** 모델을 재학습하지 않으므로 매우 가볍고 빠르게 실행됩니다.

### 1.2. 학습 파이프라인 (Training Pipeline)

- **핵심 파일:** `train.py`
- **역할:** 모델 **재학습**.
- **실행 주기:** 매일 또는 매주 (가끔 실행).
- **동작 방식:**
    1. GCS에서 전체 원본 데이터베이스를 로드합니다.
    2. 전체 데이터를 사용하여 모델을 **재학습**합니다.
    3. 성능이 검증된 새 모델을 `tuned_models/` 폴더에 `.pkl` 파일로 덮어씁니다.
- **특징:** 무거운 학습 작업을 전담하며, 예측 파이프라인의 성능을 최신 상태로 유지합니다.

---

## 2. 표준 작업 절차 (Standard Workflow)

### 2.1. 예측 파이프라인 배포/업데이트

`main.py` 또는 관련 웹 로직 수정 시, 다음 명령어를 통해 Cloud Run 서비스를 업데이트합니다.

```bash
# 1. Dockerfile이 도커 환경에 맞게 설정되었는지 확인
# 2. Cloud Build를 통해 빌드 및 배포 실행
gcloud builds submit --config cloudbuild.yaml .
```

- **트리거 방식:** 배포된 Cloud Run 서비스의 URL을 **매시간** 호출하도록 설정된 `Cloud Scheduler`에 의해 자동으로 실행됩니다.

### 2.2. 모델 재학습 실행

`train.py` 또는 모델링 관련 로직 수정 시, 다음 방법으로 학습 파이프라인을 실행합니다.

```bash
# (방법 1) Cloud Shell에서 직접 실행 (간단한 테스트용)
python3 train.py

# (방법 2) Cloud Build를 통해 실행 (권장)
# 별도의 학습용 cloudbuild-train.yaml을 만들거나, gcloud run jobs를 사용하는 것이 좋음.
# 예시: gcloud builds submit --config cloudbuild-train.yaml .
```

- **트리거 방식:** **매주** 실행되도록 설정된 별도의 `Cloud Scheduler`에 의해 자동 실행되도록 구성해야 합니다.

---

## 3. 변경 이력 (Changelog)

- **2025-08-07:**
    - **변경 내용:** 기존의 단일 파이프라인을 **예측**과 **학습** 파이프라인으로 분리하는 대규모 리팩토링 수행.
    - **주요 변경 파일:** `main.py`, `prediction/xgboost.py`, `train.py` (신규).
    - **사유:** 시스템 효율성, 확장성 및 안정성 확보.
