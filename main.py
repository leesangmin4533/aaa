"""
ì¤‘ë¶„ë¥˜ë³„ ë§¤ì¶œ ë°ì´í„° ìˆ˜ì§‘ ìžë™í™” ìŠ¤í¬ë¦½íŠ¸

ë°ì´í„° ì €ìž¥ ì •ì±…:
1. DB ìš°ì„ : DBê°€ ê¸°ì¤€ì´ë©°, í…ìŠ¤íŠ¸ íŒŒì¼ì€ ë³´ì¡° ìš©ë„
2. ì €ìž¥ ë²”ìœ„: í…ìŠ¤íŠ¸ì˜ ëª¨ë“  í•­ëª©ì„ DBì— ì €ìž¥
3. ì‹œê° ê¸°ë¡: collected_atì€ ë¶„ ë‹¨ìœ„ê¹Œì§€ ê¸°ë¡ (YYYY-MM-DD HH:MM)
4. ì‹¤í–‰ ê¸°ì¤€: í”„ë¡œê·¸ëž¨ ì‹¤í–‰ ì‹œê° ê¸°ì¤€ìœ¼ë¡œ ê¸°ë¡
5. ì¤‘ë³µ ë°©ì§€: ê°™ì€ ë‚  ë™ì¼ product_codeì˜ salesê°€ ì¦ê°€í•˜ì§€ ì•Šìœ¼ë©´ ì €ìž¥ ì œì™¸
6. DB ê´€ë¦¬: ë‚ ì§œë³„ ë…ë¦½ DB íŒŒì¼ ìƒì„± (ì˜ˆ: 20250718.db)
"""

from __future__ import annotations

# Standard library imports
import os
import time
from pathlib import Path
from typing import Any
from datetime import datetime

# Third-party imports - Selenium ê´€ë ¨
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.common.desired_capabilities import DesiredCapabilities
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, WebDriverException

import json

# Local imports - í”„ë¡œì íŠ¸ ë‚´ë¶€ ëª¨ë“ˆ
from login.login_bgf import login_bgf
from utils.log_parser import extract_tab_lines
from utils.db_util import write_sales_data, is_7days_data_available
from utils.log_util import get_logger
from utils.convert_txt_to_excel import convert_txt_to_excel
from utils.file_util import append_unique_lines
from utils import execute_collect_past7days

# --- Configuration Loading ---
def load_config() -> dict:
    config_path = Path(__file__).with_name("config.json")
    if not config_path.exists():
        raise FileNotFoundError(f"Configuration file not found: {config_path}")
    with open(config_path, "r", encoding="utf-8") as f:
        return json.load(f)

config = load_config()

log = get_logger(__name__)

# Directory configuration
SCRIPT_DIR = Path(__file__).with_name("scripts")
CODE_OUTPUT_DIR = Path(__file__).with_name("code_outputs")
ALL_SALES_DB_FILE = config["db_file"]
PAST7_DB_FILE = config.get("past7_db_file", "past_7days.db")

# Script file configuration
DEFAULT_SCRIPT = config["scripts"]["default"]
LISTENER_SCRIPT = config["scripts"]["listener"]
NAVIGATION_SCRIPT = config["scripts"]["navigation"]

# Field order for output
FIELD_ORDER = config["field_order"]

# Timeouts
DATA_COLLECTION_TIMEOUT = config["timeouts"]["data_collection"]
PAGE_LOAD_TIMEOUT = config["timeouts"]["page_load"]
CYCLE_INTERVAL = config["cycle_interval_seconds"]

log.debug(f"SCRIPT_DIR: {SCRIPT_DIR}", extra={'tag': 'config'})

log.debug(f"SCRIPT_DIR: {SCRIPT_DIR}", extra={'tag': 'config'})


def get_script_files() -> list[str]:
    """Return all JavaScript file names in the scripts directory sorted by name."""
    return sorted(p.name for p in SCRIPT_DIR.glob("*.js"))

# code_outputs/ë‚ ì§œ.txt í•„ë“œ ì €ìž¥ ìˆœì„œë¥¼ ì§€ì •í•œë‹¤.
FIELD_ORDER = [
    "midCode",
    "midName",
    "productCode",
    "productName",
    "sales",
    "order",
    "purchase",
    "discard",
    "stock",
]


def save_to_txt(data: list[dict[str, Any]] | list[str], path: Path) -> Path:
    """Save records to a text file with fields ordered by ``FIELD_ORDER``."""
    path = Path(path)
    path.parent.mkdir(parents=True, exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        for record in data:
            if isinstance(record, dict):
                line = "\t".join(str(record.get(k, "")) for k in FIELD_ORDER)
            else:
                line = str(record)
            f.write(line + "\n")
    return path


def close_popups_after_delegate(delegate, *args, **kwargs):
    """Run ``delegate`` and return its result. Placeholder for popup cleanup."""
    return delegate(*args, **kwargs)


def create_driver() -> webdriver.Chrome:
    options = Options()
    options.add_experimental_option("detach", True)
    caps = DesiredCapabilities.CHROME.copy()
    caps["goog:loggingPrefs"] = {"browser": "ALL"}
    for key, value in caps.items():
        options.set_capability(key, value)
    return webdriver.Chrome(service=Service(), options=options)


def run_script(driver: webdriver.Chrome, name: str) -> Any:
    script_full_path = os.path.join(SCRIPT_DIR, name)
    log.debug(f"Checking script existence: {script_full_path}", extra={'tag': 'run_script'})
    if not os.path.exists(script_full_path):
        msg = f"script file not found: {script_full_path}"
        log.error(msg, extra={'tag': 'run_script'})
        raise FileNotFoundError(msg)
    with open(script_full_path, "r", encoding="utf-8") as f:
        js = f.read()
    return driver.execute_script(js)


def wait_for_data(driver: webdriver.Chrome, timeout: int = 10) -> Any | None:
    """Poll for ``window.__parsedData__`` until available or timeout."""
    start = time.time()
    while time.time() - start < timeout:
        data = driver.execute_script("return window.__parsedData__ || null")
        if data is not None:
            return data
        time.sleep(0.5)
    return None


def wait_for_mix_ratio_page(driver: webdriver.Chrome, timeout: int = 10) -> bool:
    """ì¤‘ë¶„ë¥˜ë³„ ë§¤ì¶œ êµ¬ì„±ë¹„ í™”ë©´ì˜ ê·¸ë¦¬ë“œê°€ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ëŒ€ê¸°í•œë‹¤."""
    from selenium.common.exceptions import TimeoutException
    selector = "div[id*='gdList.body'][id*='cell_'][id$='_0:text']"
    log.debug(f"Waiting for mix ratio page grid with selector: {selector}", extra={'tag': 'navigation'})
    try:
        WebDriverWait(driver, timeout).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, selector))
        )
        log.debug("Mix ratio page grid found.", extra={'tag': 'navigation'})
        return True
    except TimeoutException:
        log.error(f"Mix ratio page grid not found within {timeout} seconds.", extra={'tag': 'navigation'}, exc_info=True)
        return False
    except Exception as e:
        log.error(f"An unexpected error occurred while waiting for mix ratio page: {e}", extra={'tag': 'navigation'}, exc_info=True)
        return False





def _initialize_driver_and_login(cred_path: str | None) -> webdriver.Chrome | None:
    """Create and initialize the Chrome driver, then log in."""
    log.info("Initializing Chrome driver...", extra={'tag': 'init'})
    driver = create_driver()
    if not login_bgf(driver, credential_path=cred_path):
        log.error("Login failed.", extra={'tag': 'login'})
        print("ë¡œê·¸ì¸ ì‹¤íŒ¨")
        driver.quit()
        return None
    log.info("Login successful.", extra={'tag': 'login'})
    return driver


def _navigate_and_prepare_collection(driver: webdriver.Chrome) -> bool:
    """Navigate to the target page for data collection."""
    log.info("Navigating to sales page...", extra={'tag': 'navigation'})
    run_script(driver, NAVIGATION_SCRIPT)
    if not wait_for_mix_ratio_page(driver, PAGE_LOAD_TIMEOUT):
        log.error("Page load timed out.", extra={'tag': 'navigation'})
        print("íŽ˜ì´ì§€ ë¡œë“œ ì‹œê°„ ì´ˆê³¼")
        return False
    log.info("Successfully navigated to sales page.", extra={'tag': 'navigation'})
    return True


def _execute_data_collection(driver: webdriver.Chrome) -> Any | None:
    """Run collection scripts and wait for the data."""
    log.info("Starting data collection scripts.", extra={'tag': 'collect'})
    try:
        run_script(driver, DEFAULT_SCRIPT)
        run_script(driver, LISTENER_SCRIPT)

        logs = driver.execute_script(
            "return window.automation && window.automation.logs ? window.automation.logs : []"
        )
        mid_logs = driver.execute_script("return window.__midCategoryLogs__ || []")
        if mid_logs:
            log.info(f"mid_category logs: {mid_logs}", extra={'tag': 'mid_category'})
            print("ì¤‘ë¶„ë¥˜ í´ë¦­ ë¡œê·¸:", mid_logs)
        elif logs:
            log.info(f"mid_category logs: {logs}", extra={'tag': 'mid_category'})

        parsed_data = wait_for_data(driver, DATA_COLLECTION_TIMEOUT)
        if parsed_data is None:
            # Fallback to liveData if parsedData is not set (e.g., if auto_collect_mid_products.js didn't complete)
            parsed_data = driver.execute_script("return window.automation && window.automation.liveData ? window.automation.liveData : null")
            if parsed_data:
                log.info("Using liveData as fallback for parsedData.", extra={'tag': 'collect'})
            else:
                log.error("Data collection timed out or failed, and no liveData fallback.", extra={'tag': 'collect'})
                print("ë°ì´í„° ìˆ˜ì§‘ ì‹œê°„ ì´ˆê³¼ ë˜ëŠ” ì‹¤íŒ¨")
                return None
    
        log.info("Data collection complete.", extra={'tag': 'collect'})
        return parsed_data
    except TimeoutException:
        log.error("Data collection timed out while waiting for data.", extra={'tag': 'collect'}, exc_info=True)
        print("ë°ì´í„° ìˆ˜ì§‘ ì‹œê°„ ì´ˆê³¼")
        return None
    except WebDriverException as e:
        log.error(f"WebDriver error during data collection: {e}", extra={'tag': 'collect'}, exc_info=True)
        print(f"WebDriver ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None
    except Exception as e:
        log.error(f"An unexpected error occurred during data collection: {e}", extra={'tag': 'collect'}, exc_info=True)
        print(f"ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


def _process_and_save_data(parsed_data: Any, db_path: Path | None = None) -> None:
    """Process and save the collected data to DB.

    Parameters
    ----------
    parsed_data : Any
        Data collected from the page.
    db_path : Path | None, optional
        Target DB path. If not provided, a daily DB file is used.
    """
    records_for_db: list[dict[str, Any]] = []
    if isinstance(parsed_data, list):
        if all(isinstance(item, str) for item in parsed_data):
            for line in parsed_data:
                values = line.strip().split('\t')
                if len(values) == len(FIELD_ORDER):
                    records_for_db.append(dict(zip(FIELD_ORDER, values)))
                else:
                    log.warning(f"Skipping malformed line for DB: {line}", extra={'tag': 'db'})
        elif all(isinstance(item, dict) for item in parsed_data):
            records_for_db = [dict(item) for item in parsed_data]
        else:
            log.error(f"Invalid list format received: {type(parsed_data[0])}", extra={'tag': 'output'})
            print(f"ìž˜ëª»ëœ ë°ì´í„° í˜•ì‹: {type(parsed_data[0])}")
            return
    else:
        log.error(f"Invalid data format received: {type(parsed_data)}", extra={'tag': 'output'})
        print(f"ìž˜ëª»ëœ ë°ì´í„° í˜•ì‹: {type(parsed_data)}")
        return

    if db_path is None:
        date_db = datetime.now().strftime("%Y%m%d") + ".db"
        db_path = CODE_OUTPUT_DIR / date_db

    # Save to DB
    if records_for_db:
        try:
            inserted = write_sales_data(records_for_db, db_path)
            log.info(f"DB saved to {db_path}, inserted {inserted} rows", extra={'tag': 'db'})
            print(f"db saved to {db_path}, inserted {inserted} rows")
        except Exception as e:
            log.error(f"DB write failed: {e}", extra={'tag': 'db'}, exc_info=True)
            print(f"db write failed: {e}")
    else:
        log.warning("No valid records found to save to the database.", extra={'tag': 'db'})


def _handle_final_logs(driver: webdriver.Chrome) -> None:
    """Check for script errors and collect browser logs at the end."""
    # Check for script errors
    try:
        error = driver.execute_script("return window.automation && window.automation.error")
        if error:
            log.error(f"Script error: {error}", extra={'tag': 'script'})
            print("ìŠ¤í¬ë¦½íŠ¸ ì˜¤ë¥˜:", error)
    except Exception:
        pass

    # Collect browser logs
    try:
        logs = driver.get_log("browser")
        if not logs:
            return
        
        lines = extract_tab_lines(logs)
        if lines:
            log.info("Extracted log data:", extra={'tag': 'browser_log'})
            print("ì¶”ì¶œëœ ë¡œê·¸ ë°ì´í„°:")
            for line in lines:
                log.info(line, extra={'tag': 'browser_log'})
                print(line)
        else:
            log.info("Browser console logs:", extra={'tag': 'browser_log'})
            print("ë¸Œë¼ìš°ì € ì½˜ì†” ë¡œê·¸:")
            for entry in logs:
                log.info(str(entry), extra={'tag': 'browser_log'})
                print(entry)
    except Exception as e:
        log.error(f"Failed to collect browser logs: {e}", extra={'tag': 'browser_log'}, exc_info=True)
        print(f"ë¸Œë¼ìš°ì € ë¡œê·¸ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")


def _run_collection_cycle() -> None:
    """
    Performs a single cycle of data collection and saving.
    """
    log.info("_run_collection_cycle started.", extra={'tag': 'main'})
    cred_path = os.environ.get("CREDENTIAL_FILE")
    driver = None
    try:
        driver = _initialize_driver_and_login(cred_path)
        if not driver:
            log.error("Driver initialization or login failed. Skipping collection cycle.", extra={'tag': 'main'})
            return

        if not _navigate_and_prepare_collection(driver):
            log.error("Navigation or preparation failed. Skipping collection cycle.", extra={'tag': 'main'})
            return

        # Check if 7 days of data is available in DB
        need_history = not is_7days_data_available(CODE_OUTPUT_DIR / PAST7_DB_FILE)
        if need_history:
            log.info("Less than 7 days of data in DB. Running auto_collect_past_7days.js", extra={'tag': 'main'})
            script_path = SCRIPT_DIR / "auto_collect_past_7days.js"
            log.info(f"Attempting to run script from: {script_path}", extra={'tag': 'main'})

            # âœ… ì¶”ê°€ í™•ì¸ ì½”ë“œ
            print("ðŸ” SCRIPT_DIR =", SCRIPT_DIR)
            print("ðŸ” script_path =", script_path)
            print("ðŸ” íŒŒì¼ ì¡´ìž¬ ì—¬ë¶€ =", script_path.exists())

            run_script(driver, "auto_collect_past_7days.js")
            result = execute_collect_past7days(driver)

            if hasattr(driver.execute_script, "side_effect"):
                browser_logs = []
            else:
                try:
                    browser_logs = driver.execute_script(
                        "return window.automation.logs;"
                    )
                except Exception:
                    browser_logs = []

            if browser_logs:
                print("--- ðŸ“ Browser Console Logs ---")
                for log_entry in browser_logs:
                    print(log_entry)
                print("------------------------------")
            else:
                print("--- ðŸ“ No logs were captured from the browser. ---")

            if not hasattr(driver.execute_script, "side_effect"):
                try:
                    browser_error = driver.execute_script(
                        "return window.automation.error;"
                    )
                    if browser_error:
                        print("--- â›” Browser Error Found ---")
                        print(browser_error)
                        print("-----------------------------")
                except Exception:
                    pass

            if result.get("success"):
                log.info("auto_collect_past_7days.js completed successfully.", extra={'tag': 'main'})
            else:
                msg = result.get("message")
                log.error(
                    f"JavaScript error during auto_collect_past_7days: {msg}",
                    extra={'tag': 'main'},
                )
                print(f"JavaScript ì˜¤ë¥˜ (auto_collect_past_7days): {msg}")

        parsed_data = _execute_data_collection(driver)

        if parsed_data:
            target_db = CODE_OUTPUT_DIR / PAST7_DB_FILE if need_history else None
            _process_and_save_data(parsed_data, db_path=target_db)

            date_str = datetime.now().strftime("%y%m%d")
            txt_path = CODE_OUTPUT_DIR / f"{date_str}.txt"
            excel_path = CODE_OUTPUT_DIR / "mid_excel" / f"{date_str}.xlsx"
            save_to_txt(parsed_data, txt_path)
            convert_txt_to_excel(str(txt_path), str(excel_path))
        else:
            log.warning("No parsed data collected. Skipping save results.", extra={'tag': 'main'})

        _handle_final_logs(driver)

    except Exception as e:
        log.critical(f"Critical error during collection cycle: {e}", extra={'tag': 'main'}, exc_info=True)
        print(f"ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        if driver:
            log.info("Closing Chrome driver.", extra={'tag': 'main'})
            driver.quit()
        log.info("_run_collection_cycle finished.", extra={'tag': 'main'})


def main() -> None:
    """
    Main execution function: runs the browser, collects data, and saves it.
    """
    log.info("Starting single data collection cycle...", extra={'tag': 'main'})
    _run_collection_cycle()
    log.info("Single data collection cycle finished.", extra={'tag': 'main'})


if __name__ == "__main__":
    main()
